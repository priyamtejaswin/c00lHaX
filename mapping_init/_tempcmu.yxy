For quite sometime now, English language literacy has become a prerequisite for socio-economic mobility in India. This gives an advantage to the 10.6% of the population who can speak the language fluently. For the remaining 89.4%, life-changing opportunities like access to higher educa- tion, technical skills and top jobs, are hard to come by because they are not well-versed in English. Mobile technology and the Web were going to level the playing field for the majority of Indians handicapped by this language barrier. These technologies promised instant access to high-quality sources for virtually every topic. Unfortunately, content creation on the Internet is biased towards popular languages.
For example, while 57% (more than 692 million people as per the 2011 census) of India’s population speaks Hindi, only 0.2% (113,000) of Wikipedia articles are available in Hindi. More often than not, people who could really benefit from the Web cannot use it, or even explore it, because of this language barrier.
Ever since I started my undergraduate in Computer Science and Engineering in 2012, I have wanted to help such people. As a sci-fi fan who started programming before high-school, I had grand visions of building Star Trek like “universal translators” for the Web.
My undergraduate gave me a strong foundation in theory and applied research to prepare me for pursuing my dream. I took relevant CS, math and AI coursework, and focussed on applying concepts therein to real-world NLP problems. In 2014, I worked with Prof. Vijayarajan’s group at VIT Vellore researching to improve search retrieval using ontologies. Our work was published in the Springer HCIS Journal in 2016. My main contributions were in designing the evaluation experiments and implementing the retrieval models. This was my first research project, and I learnt how to arrive at the right problem statement, build hypotheses, gather data, design experiments and analyse findings.
In 2015, I applied my learnings to my first independent research project. For the ACM iKDD conference, I led my team in building a real-time framework which would use social media for identifying road-traffic. We used state-of-the-art NLP techniques on Tweets to extract locations, roads and traffic severity automatically in real-time. As the team leader, I designed the layouts for the system and all core components. I also took the responsibility of implementing and training all the ML models used in our system — text parsing, entity extraction, traffic prediction and text clustering. Our paper won the conference Data Challenge track. This was one of the first research attempts to successfully crowd-source traffic information in India.
Keen to further hone my research skills, I interned under Prof. Christo Wilson at Northeastern University, Boston as a research-assistant. Our study on the Amazon Marketplace focussed on deconstructing the BuyBox algorithm and measuring the effects of algorithmic-pricing to make it more transparent for buyers and sellers. I had two main contributions in this study. The first was to build a black-box model of the Amazon BuyBox algorithm. This gives sellers the probability of their listings to win the BuyBox. Secondly, I did empirical analysis to help sellers understand the broad effects of algorithmic-pricing on revenue.
With time, my professional goal matured: to build robust NLP systems for machine translation and question-answering. I was now eagerly looking for the right opportunities. In 2016, after graduating, I joined Flipkart — India’s largest e-commerce platform — as a Data Scientist. Two main factors motivated me to join Flipkart. The first was the scale at which Flipkart operated; I am now skilled at developing and deploying machine learning models in Python and Spark to serve over hundred million users. The second was Flipkart’s mission to use technology to empower people from rural and semi-urban areas, plagued by illiteracy and unfamiliarity with English. This had a fit with my goals.
Over the last three years, I’ve gained invaluable insights on the difficulties such users face in ex- pressing themselves clearly in English while interacting with NLP systems. As a result, downstream NLP systems struggle to understand the intent of the users and fail to return relevant results.
At Flipkart, I have purposefully picked up projects which can alleviate similar difficulties. One of my earliest projects was to identify the unmet customer demand from poorly formed search queries. This involved researching and applying short-text clustering techniques which were robust to spell- errors, mixed languages and bad grammar. My recent research involves understanding unstructured customer addresses for improving the delivery experience and geocoding performance. With my team, I developed new approaches for spell-correction, address chunking and geocoding because the state-of-the-art simply failed when the addresses were typed erroneously or when the tokens were out of order. The updated Geocoding framework (patent application submitted) improves the precision and recall over the state-of-the-art by 18% and 35% respectively.
From my work in the last three years at Flipkart, I have identified two major challenges in the state of current research in NLP. It often fails to consider the real-world interaction scenarios in developing countries where user input is rarely devoid of errors, while being grammatically incorrect and ill-formed. At Flipkart, I built systems to tackle this. The second challenge is that all state- of-the-art solutions require massive amounts of labelled data — a rarity for the regional languages predominantly used in countries like India. This is what I want to tackle next.
To truly realise my vision of building robust NLP systems for regional languages, I need to work with approaches that require minimal labelled data. Such “low-resource learning” is already catching the attention of researchers. The last two years have seen a lot of ground being covered on unsupervised machine translation, zero-shot learning and transfer learning for different NLP tasks. These are the topics I am keen to work on. While Flipkart gave me a great opportunity to hone my skills and learn from experienced mentors, I have realised that I need a focussed master’s degree before I can start contributing in this area and work towards my goals.
CMU is my top choice for a master’s program. It has a world-class institute for Language Technologies where faculty and students are actively pursuing research that aligns with my goals. Prof. Graham Neubig’s research on low-resource languages is particularly inspiring. His group has proposed novel state-of-the-art methods for a variety of NLP tasks for low-resource languages. I would love to have an opportunity to work with his group.
After my degree, I want to return to the industry and apply my skills to solve real-world chal- lenges in information retrieval. Given my undergraduate research background and strong industry experience thereafter, the MIIS program at CMU-LTI will give me an opportunity to further expand my knowledge, contribute to state-of-the-art NLP research and work towards my goal of making information accessible to everyone.
