{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Various Parts of HMM\n",
    "References:\n",
    "- <https://www.cs.sjsu.edu/~stamp/RUA/HMM.pdf> - This explains the MM + HMM model with good motivation. It also describes the 3 HMM problems and their solutions but does not explain their derivations.\n",
    "- <https://en.wikipedia.org/wiki/Hidden_Markov_model> - This has further references and links to the solutions used for solving the HMM problems. Some (like the entry on the `forward algotithm`) are well written and can make things clearer.\n",
    "\n",
    "My aim here is to derive the solutions for each of the HMM problems and apply them to toy examples. I've tried to be as lucid with the Math, code and the derivations as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Toy example 1**\n",
    "\n",
    "- Two hidden states : [1_Hot, 2_Cold]\n",
    "- Three observed states : [0_Small, 1_Medium, 2_Large]\n",
    "- Init Probability : $\\pi = [0.6, 0.4]$\n",
    "- Transition Matrix $A$\n",
    "\n",
    "| t-1 => t | s0 | s_hot | s_cold |\n",
    "|----------|----|-------|--------|\n",
    "| **s0**       | 0  | 0.6   | 0.4    |\n",
    "| **s_hot**    | 0  | 0.7   | 0.3    |\n",
    "| **s_cold**   | 0  | 0.4   | 0.6    |\n",
    "\n",
    "\n",
    "- Emission Matrix $B$\n",
    "\n",
    "| zt => xt | 0_small | 1_medium | 2_large |\n",
    "|----------|---------|----------|---------|\n",
    "| s0       | NA       | NA        | NA       |\n",
    "| s_hot    | 0.1     | 0.4      | 0.5     |\n",
    "| s_cold   | 0.7     | 0.2      | 0.1     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## In numpy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocStates = 2\n",
    "vocObs = 3\n",
    "\n",
    "trA = np.array(\n",
    "    [\n",
    "        [0, 0.6, 0.4],\n",
    "        [0, 0.7, 0.3],\n",
    "        [0, 0.4, 0.6]\n",
    "    ]\n",
    ")\n",
    "\n",
    "emB = np.array(\n",
    "    [\n",
    "        [None, None, None],\n",
    "        [0.1, 0.4, 0.5],\n",
    "        [0.7, 0.2, 0.1]\n",
    "    ]\n",
    ")\n",
    "\n",
    "obX = [0, 1, 0, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "Given $A, B, \\pi$ and a observed sequence $\\vec{x} = (0, 1, 0, 2)$, what is the probability of observing this sequence?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As derived, for a sequence $\\vec x$ given $A, B$, we can arrive at the following:\n",
    "$$\n",
    "P(\\vec x; A,B) = \\sum_{\\vec z} P(\\vec x, \\vec z; A,B) \\\\\n",
    "= \\sum_{\\vec z} \\big(\\prod_{t=1}^T B_{z_t, x_t}\\big) \\big(\\prod_{t=1}^T A_{z_{t-1}, z_t}\\big) \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This solution involves considering every possible state assignment combination for the output sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 1, 1) 0.000412 0.0004116\n",
      "(1, 1, 1, 2) 3.5e-05 0.00044688\n",
      "(1, 1, 2, 1) 0.000706 0.00115248\n",
      "(1, 1, 2, 2) 0.000212 0.00136416\n",
      "(1, 2, 1, 1) 5e-05 0.0014145599999999998\n",
      "(1, 2, 1, 2) 4e-06 0.0014188799999999998\n",
      "(1, 2, 2, 1) 0.000302 0.0017212799999999997\n",
      "(1, 2, 2, 2) 9.1e-05 0.0018119999999999998\n",
      "(2, 1, 1, 1) 0.001098 0.0029095999999999996\n",
      "(2, 1, 1, 2) 9.4e-05 0.0030036799999999995\n",
      "(2, 1, 2, 1) 0.001882 0.004885279999999999\n",
      "(2, 1, 2, 2) 0.000564 0.005449759999999999\n",
      "(2, 2, 1, 1) 0.00047 0.005920159999999999\n",
      "(2, 2, 1, 2) 4e-05 0.005960479999999999\n",
      "(2, 2, 2, 1) 0.002822 0.008782879999999998\n",
      "(2, 2, 2, 2) 0.000847 0.009629599999999999\n",
      "0.009629599999999999\n"
     ]
    }
   ],
   "source": [
    "total_prob = 0\n",
    "for i in range(1, 3):\n",
    "    for j in range(1, 3):\n",
    "        for k in range(1, 3):\n",
    "            for l in range(1, 3):\n",
    "                zprob = 1.0\n",
    "                zseq = (i, j, k, l)\n",
    "                for t, (z, x) in enumerate(zip(zseq, obX)):\n",
    "                    _b = emB[z, x]\n",
    "                    \n",
    "                    if t == 0:\n",
    "                        zprev = 0\n",
    "                    else:\n",
    "                        zprev = zseq[t-1]\n",
    "                    \n",
    "                    _a = trA[zprev, z]\n",
    "                    \n",
    "                    zprob = zprob * _a * _b\n",
    "                    \n",
    "                total_prob += zprob\n",
    "                print zseq, round(zprob, 6), total_prob\n",
    "                \n",
    "print total_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This solution is naive. We are iterating over every combination of $\\vec z$ over time. Let's see if it can be done faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task is to find $P(\\vec x)$ (matrices $A$, $B$ omitted for brevity). This can be expressed as\n",
    "$$\n",
    "P(\\vec x) = \\sum_{z_t} P(z_t, \\vec x)  \\tag0\n",
    "$$\n",
    "\n",
    "The equation above is true for any expression. Let's now try to expand $P(z_t, \\vec x)$ in terms of our emission and transition terms ...\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(z_t, x_{1:t}) &= \\sum_{z_{t-1}} P(z_t, z_{t-1}, x_{1:t}) \\tag1 \\\\\n",
    "&= \\sum_{z_{t-1}} P(x_t, z_t, z_{t-1}, x_{t-1}, x_{t-2}, ... , x_1) \\tag2 \\\\\n",
    "&= \\sum_{z_{t-1}} P(x_t | z_t) P(z_t, z_{t-1}, x_{1:t-1}) \\tag3 \\\\\n",
    "&= \\sum_{z_{t-1}} P(x_t | z_t) P(z_t | z_{t-1}) P(z_{t-1}, x_{1:t-1}) \\tag4 \\\\\n",
    "&= P(x_t | z_t) \\sum_{z_{t-1}} P(z_t | z_{t-1}) P(z_{t-1}, x_{1:t-1}) \\tag5\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In eq 1, we introduce a new hidden state var from previous timestep. Eq 2 simple expands $x_{1:t}$ before applying the Markov assumptions. In eq 3 we apply the emission prob. assumption and in eq 4 we apply the transition prob. assumption. Finally, in eq 5, we can take $P(x_t, z_t)$ out of the summand since we are iterating over values of $z_{t-1}$ only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that there is a recurrence b/w EQ1 and EQ5. If we define $\\alpha_z(t)$ to be $P(z_t, x_{1:t})$, then we can rewrite EQ 5 as follows:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(z_t, x_{1:t}) &= P(x_t | z_t) \\sum_{z_{t-1}} P(z_t | z_{t-1}) P(z_{t-1}, x_{1:t-1}) \\\\\n",
    "\\rightarrow \\alpha_z(t) &= P(x_t | z_t) \\sum_{z_{t-1}} P(z_t | z_{t-1}) \\alpha_z(t-1) \\\\\n",
    "&= B_{z_t, x_t} \\sum_{z_{t-1}} A_{z_t, z_{t-1}} \\alpha_z(t-1)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This expression only involves summing over all possible states of $z_i$, which in our example is 2. Our original expression EQ 0, thus becomes\n",
    "\n",
    "$$\n",
    "P(\\vec x) = \\sum_{z_t} P(z_t, \\vec x) = \\sum_z \\alpha_z(t = T)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are no longer considering all possible combinations of the entire sequence of hidden states, but rather, the possible values of $z$, which in our example is 2. And to calculate $\\alpha(T)$, we will have to iterate over all timesteps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "_toy = \"\"\"\n",
    "====\n",
    "Init\n",
    "====\n",
    "_|_H_|_L_\n",
    "*|0.5|0.5\n",
    "\n",
    "============\n",
    "Transmission\n",
    "============\n",
    "_|_H_|_L_\n",
    "H|0.5|0.5\n",
    "L|0.4|0.6\n",
    "\n",
    "========\n",
    "Emission\n",
    "========\n",
    "_|_A_|_C_|_G_|_T_\n",
    "H|0.2|0.3|0.3|0.2\n",
    "L|0.3|0.2|0.2|0.3\n",
    "\n",
    "========\n",
    "Observed\n",
    "========\n",
    "[G G C A]\n",
    "\"\"\"\n",
    "states = ['H', 'L']\n",
    "genes = ['A', 'C', 'G', 'T']\n",
    "\n",
    "inits = [0.5, 0.5]\n",
    "\n",
    "trans = np.array(\n",
    "    [\n",
    "        [0.5, 0.5],\n",
    "        [0.4, 0.6]\n",
    "    ]\n",
    ")\n",
    "emmit = np.array(\n",
    "    [\n",
    "        [0.2, 0.3, 0.3, 0.2],\n",
    "        [0.3, 0.2, 0.2, 0.3]\n",
    "    ]\n",
    ")\n",
    "\n",
    "obsX = [2, 2, 1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 0, 0) 0.0003375 0.0003375\n",
      "(0, 0, 0, 1) 0.00050625 0.00084375\n",
      "(0, 0, 1, 0) 0.00018 0.00102375\n",
      "(0, 0, 1, 1) 0.0004049999999999999 0.00142875\n",
      "(0, 1, 0, 0) 0.00018 0.00160875\n",
      "(0, 1, 0, 1) 0.00027 0.00187875\n",
      "(0, 1, 1, 0) 0.000144 0.00202275\n",
      "(0, 1, 1, 1) 0.000324 0.00234675\n",
      "(1, 0, 0, 0) 0.00018000000000000004 0.00252675\n",
      "(1, 0, 0, 1) 0.00027 0.0027967499999999998\n",
      "(1, 0, 1, 0) 9.600000000000004e-05 0.00289275\n",
      "(1, 0, 1, 1) 0.00021600000000000005 0.00310875\n",
      "(1, 1, 0, 0) 0.000144 0.00325275\n",
      "(1, 1, 0, 1) 0.00021600000000000002 0.00346875\n",
      "(1, 1, 1, 0) 0.00011520000000000001 0.0035839500000000002\n",
      "(1, 1, 1, 1) 0.0002592 0.00384315\n"
     ]
    }
   ],
   "source": [
    "## Priyam, forget whatever shit you wrote on top.\n",
    "## We define `\\alpha` for every timestep AND every hidden state ==> `\\alpha_i(t)`.\n",
    "total_prob = 0\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        for k in range(2):\n",
    "            for l in range(2):\n",
    "                prob = 1.0\n",
    "                zstates = (i, j, k, l)\n",
    "                \n",
    "                for t, (z, x) in enumerate(zip(zstates, obsX)):\n",
    "                    if t == 0:\n",
    "                        prob = prob * inits[z] * emmit[z, x]\n",
    "                    else:\n",
    "                        prob = prob * trans[zstates[t-1], z] * emmit[z, x]\n",
    "                \n",
    "                total_prob += prob\n",
    "                print zstates, prob, total_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====\n",
      "Init\n",
      "====\n",
      "_|_H_|_L_\n",
      "*|0.5|0.5\n",
      "\n",
      "============\n",
      "Transmission\n",
      "============\n",
      "_|_H_|_L_\n",
      "H|0.5|0.5\n",
      "L|0.4|0.6\n",
      "\n",
      "========\n",
      "Emission\n",
      "========\n",
      "_|_A_|_C_|_G_|_T_\n",
      "H|0.2|0.3|0.3|0.2\n",
      "L|0.3|0.2|0.2|0.3\n",
      "\n",
      "========\n",
      "Observed\n",
      "========\n",
      "[G G C A]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print _toy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0038431500000000005\n",
      "Matches brute force!\n"
     ]
    }
   ],
   "source": [
    "for t,x in enumerate(obsX):\n",
    "    if t == 0:\n",
    "        alpha_prev = []\n",
    "        for i in range(2):\n",
    "            alpha_prev.append(inits[i] * emmit[i, x])\n",
    "            \n",
    "    else:\n",
    "        alpha_new = []\n",
    "        for i in range(2):\n",
    "            _jsum = 0\n",
    "            for j in range(2):\n",
    "                _jsum += alpha_prev[j] * trans[j, i]\n",
    "            \n",
    "            alpha_new.append(_jsum * emmit[i, x])\n",
    "        \n",
    "        alpha_prev = deepcopy(alpha_new)\n",
    "        \n",
    "print sum(alpha_new)\n",
    "assert round(total_prob, 6) == round(sum(alpha_new), 6)\n",
    "print \"Matches brute force!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have it working, let's try deriving the *alpha-pass* algorithm again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following EQ 5, we can express the joint probability $P(z_t, x_{1:t})$ as \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(z_t, x_{1:t}) &= P(x_t | z_t) \\sum_{z_{t-1}} P(z_t | z_{t-1}) P(z_{t-1}, x_{1:t-1}) \\tag6\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, $z_t$ is simply a random variable whose value exists in the set of state values $S$; the joint distribution \"table\" is defined for all possible values that $z_t$ can have. Concretely, we can define the joint probability for a particular state value $s_i$ as:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(z_t=s_i, x_{1:t}) &= P(x_t | z_t=s_i) \\sum_{s_j \\in S} P(z_t = s_i | z_{t-1} = s_j) \\times P(z_{t-1} = s_j, x_{1:t-1}) \\tag7\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this view, we can define $\\alpha_t(s_i)$, as the probability of the observed partial sequnce upto time $t$ where $z_t = s_i$ :\n",
    "\n",
    "$$\n",
    "\\alpha_t(s_i) = P(z_t = s_i, x_{1:t}) \\tag8\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can re-write EQ7 in terms of $\\alpha, A, B$:\n",
    "\n",
    "$$\n",
    "\\alpha_t(s_i) = B_{s_i, x_t} \\sum_{s_j \\in S} A_{s_j, s_i} \\times \\alpha_{t-1}(s_j) \\tag9\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The base-case, for this recursive definition is for the first observation $x_1$. This is simply the probability of observing $x_1$ for all possible state assignment to $z_1$.\n",
    "\n",
    "$$\n",
    "\\alpha_1(s_i) = B_{s_i, x_1} \\pi_{s_i} \\tag{10}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using EQs 8, 9 and 10, we can express the probability of observing any sequnce $x_{1:T}$ as \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(x_{1:T}) &= \\sum_{s_i \\in S} P(x_{1:T}, z_T=s_i) \\\\\n",
    "&= \\sum_{s_i \\in S} \\alpha_T(s_i) \\tag{11}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally! We have now reduced the time-complexity from $O(|S|^T)$ to $O(|S|^2T)$. How?\n",
    "- To arrive at $\\alpha_T$, we will have to loop over all possible values of $T$.\n",
    "```python\n",
    "for t,x in enumerate(obsX):\n",
    "```\n",
    "\n",
    "- At every iteration, we will compute the intermediate value $\\alpha_t(s_i)$ for all $i$, which will require a sum over every state value $j$ from the previously computer $\\alpha_{t-1}$ (from EQ 9) -- hence the $|S|^2$.\n",
    "```python\n",
    "        alpha_new = []\n",
    "        for i in range(2): ## For current $\\alpha_t$\n",
    "            _jsum = 0\n",
    "            for j in range(2): ## From previous $\\alpha_{t-1}$\n",
    "                _jsum += alpha_prev[j] * trans[j, i]\n",
    "            \n",
    "            alpha_new.append(_jsum * emmit[i, x])\n",
    "        \n",
    "        alpha_prev = deepcopy(alpha_new)\n",
    "```\n",
    "\n",
    "Once the last `alpha_new` has been computed, the joint is simply the sum of probabilities over the states : `return sum(alpha_new)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 (a)\n",
    "Given a sequence of time $t$, what is the distribution over hidden states $P(z_t)$ at time $t$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to find $P(z_t | x_{1:t})$. This can be done easily using the result from the `forward algorithm`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "P(z_t = s_i | x_{1:t}) &= \\frac{P(z_t = s_i, x_{1:t})}{P(x_{1:t})} \\tag{12} \\\\\n",
    "&= \\frac{\\alpha_t(s_i)}{\\sum_{s_j}\\alpha_t(s_j)} \\tag{13}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 (b)\n",
    "Finding $P(z_t = s_i | x_{1:T})$ for any arbitrary $t \\in [1, T]$ is not trivial. Deriving this to the final \"optimized form\" took a while because it was not apparent what terms to factorize in the joint expression.\n",
    "\n",
    "We begin by expressing $P(z_t = s_i | x_{1:T}) \\propto P(z_t = s_i, x_{1:T})$. The equation is complete with $P(x_{1:T})$ in the denominator as in EQ.12, 13. We ignore that term for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "P(z_t = s_i | x_{1:T}) &\\propto P(z_t = s_i, x_{1:T}) \\\\\n",
    "&= P(z_t = s_i, x_{1:t}, x_{t+1:T}) \\tag{14} \\\\\n",
    "&= P(x_{t+1:T} | z_t=s_i, x_{1:t}) \\ P(z_t = s_i, x_{1:t}) \\tag{15}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In EQ. 14 15, we are trying to factorize the joint into two terms: the second term we have solved already in EQ.12. We can simplify the first term by exploiting the fact that the probability of the future observations $x_{t+1:T}$ is independent of the past observations $x_{1:t}$ given the current hidden state $z_t = s_i$. The following diagram, will make it clear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](hmm-d1small.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this, we can rewrite it to $P(x_{t+1 : T}|z_t = s_i) \\times \\alpha_t(s_i)$. Now let's estimate the first term.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(x_{t+1 : T}|z_t = s_i) &= \\frac{P(x_{t+1 : T}, z_t = s_i)}{P(z_t = s_i)} \\\\ \\\\\n",
    "&= \\sum_{s_j \\in S} P(x_{t+1:T}, z_t = s_i, z_{t+1}=s_j) / P(z_t = s_i) \\tag{16} \\\\ \\\\\n",
    "&= \\sum_{s_j \\in S} P(x_{t+1}, x_{t+2:T}, z_t = s_i, z_{t+1}=s_j) / P(z_t = s_i) \\tag{17} \\\\ \\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EQ.16 is trivial - we introduce a new state variable $z_{t+1}$. In EQ. 17, we breakdown the observed states into $x_{t+1}, x_{t+2:T}$. This will allow us to factorize the expression as a recursion of FUTURE time-steps. Continuing..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "&= \\sum_{s_j \\in S} P(x_{t+2:T} | x_{t+1}, z_t = s_i, z_{t+1}=s_j) \\times P(x_{t+1}, z_t = s_i, z_{t+1}=s_j) / P(z_t = s_i) \\tag{18} \\\\ \\\\\n",
    "&= \\sum_{s_j \\in S} P(x_{t+2:T} | z_{t+1}=s_j) \\times P(x_{t+1} | z_t = s_i, z_{t+1}=s_j) \\times P(z_t = s_i, z_{t+1}=s_j) / P(z_t = s_i) \\tag{19} \\\\ \\\\\n",
    "&= \\sum_{s_j \\in S} P(x_{t+2:T} | z_{t+1}=s_j) \\times P(x_{t+1} | z_{t+1}=s_j) \\times P(z_{t+1} = s_j | z_t = s_i) \\times P(z_t = s_i) / P(z_t = s_i) \\tag{20} \\\\ \\\\\n",
    "&= \\sum_{s_j \\in S} P(x_{t+2:T} | z_{t+1}=s_j) \\times B_{x_{t+1}, s_j} \\times A_{s_i, s_j} \\tag{21}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lots going here. \n",
    "- In EQ 19, the first term is a result of applying the concept from our last diagram -- the future observations $x_{t+2:T}$ only depend on the current hidden state $z_{t+1} = s_j$. The simplied form is the first term in EQ 20.\n",
    "- The remaining terms in EQ 19 are factors of the second joint prob term in EQ 18.\n",
    "- In EQ 20, for the second term, we apply the emission independence assumption. The next two terms in the equation are factors of the joint $P(z_t = s_i, z_{t+1} = s_j)$.\n",
    "- The last two terms in EQ 20 cancel each other and the final form in terms of our emission and transition matrices is in EQ 21."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And *now*, we finally have our recursive relation. At any time $t$ and a particular state assignment $s_i$ we define $\\beta_t(s_i) = P(x_{t+1 : T} | z_t = s_i)$. This is the probability of all future observations, given the current hidden state. Appropriately,\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(x_{t+1 : T}|z_t = s_i) &= \\sum_{s_j \\in S} P(x_{t+2:T} | z_{t+1}=s_j) \\times B_{x_{t+1}, s_j} \\times A_{s_i, s_j} \\\\ \\\\\n",
    "\\implies \\beta_t(s_i) &= \\sum_{s_j \\in S} \\beta_{t+1}(s_j) \\times B_{x_{t+1}, s_j} \\times A_{s_i, s_j} \\tag{22}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this in place, we can define the base-case at the last timestep $T$ as $\\beta_T(s_i \\in S) = 1$, since there are no observations after time $T$. We then work back starting from $T$ and use the future $\\beta$ values in each step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using EQs 12 and 14, we can now complete the expression $P(z_t = s_i | x_{1:T})$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(z_t = s_i | x_{1:T}) &= \\frac{P(z_t = s_i, x_{1:T})}{P(x_{1:T})} \\tag{joint} \\\\ \\\\\n",
    "&= \\frac{P(z_t = s_i, x_{1:t}, x_{t+1:T})}{P(x_{1:T})} \\tag{observed seq time split} \\\\ \\\\\n",
    "&= \\frac{P(x_{t+1:T} | z_t=s_i, x_{1:t}) \\ P(z_t = s_i, x_{1:t})}{P(x_{1:T})} \\tag{factoring for $\\alpha, \\beta$} \\\\ \\\\\n",
    "&= \\frac{P(x_{t+1:T} | z_t=s_i) \\ P(z_t = s_i, x_{1:t})}{P(x_{1:T})} \\tag{\"independence\" from the diagram} \\\\ \\\\\n",
    "&= \\frac{\\beta_t(s_i) \\ \\alpha_t(s_i)}{P(x_{1:T})} \\tag{23}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2(c) Viterbi\n",
    "\n",
    "With EQ 23, we can compute $P(z_t = s_i | x_{1:T})$ starting from $T$ and working back towards $t=1$. At every timestep, if we take the most probable state assignment $s_i$, we will get the most probable hidden state seequence for any observed sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, I have introduce yet another toy example before we begin. This ones from the [Forward-Backward Algorithm's Wiki page](https://en.wikipedia.org/wiki/Forward%E2%80%93backward_algorithm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = ('Healthy', 'Fever')\n",
    "end_state_ix = 2 ## last step\n",
    "inits = [0.6, 0.4]\n",
    "\n",
    "trans = np.array(\n",
    "    [\n",
    "        [0.69, 0.3, 0.01],\n",
    "        [0.4, 0.59, 0.01]\n",
    "    ]\n",
    ")\n",
    "\n",
    "outputs = ['normal', 'cold', 'dizzy']\n",
    "emmit = np.array(\n",
    "    [\n",
    "        [0.5, 0.4, 0.1],\n",
    "        [0.1, 0.3, 0.6]\n",
    "    ]\n",
    ")\n",
    "\n",
    "obsX = [0, 1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of observing sequence ['normal', 'cold', 'dizzy'] 0.00035638319999999995\n",
      "2\n",
      "ahead_beta [0.01, 0.01]\n",
      "1\n",
      "ahead_beta [0.00249, 0.00394]\n",
      "0\n",
      "ahead_beta [0.0010418399999999998, 0.00109578]\n",
      "[0.8770110375573259, 0.1229889624426741]\n",
      "[0.623228030950954, 0.3767719690490461]\n",
      "[0.2109527048413057, 0.7890472951586943]\n"
     ]
    }
   ],
   "source": [
    "## forward pass\n",
    "alphas = []\n",
    "for t, x in enumerate(obsX):\n",
    "    if t == 0: ## init prev_alpha\n",
    "        prev_alpha = []\n",
    "        for s in range(len(states)):\n",
    "            prev_alpha.append(emmit[s, x] * inits[s])\n",
    "            \n",
    "    else:\n",
    "        new_alpha = []\n",
    "        for i in range(len(states)):\n",
    "            accum = 0.0\n",
    "            for j in range(len(states)):\n",
    "                accum += prev_alpha[j] * trans[j, i]\n",
    "                \n",
    "            new_alpha.append(accum * emmit[i, x])\n",
    "        \n",
    "        prev_alpha = deepcopy(new_alpha)\n",
    "    \n",
    "    alphas.append(prev_alpha)\n",
    "            \n",
    "p_obs = sum([new_alpha[s]*trans[s, end_state_ix] for s in range(len(states))])\n",
    "print \"Probability of observing sequence\", [outputs[x] for x in obsX], p_obs\n",
    "\n",
    "## backward pass\n",
    "betas = []\n",
    "for t in range(len(obsX))[::-1]:\n",
    "    print t\n",
    "    if t == (len(obsX)-1):\n",
    "        ahead_beta = []\n",
    "        for s in range(len(states)):\n",
    "            ahead_beta.append(trans[s, end_state_ix])\n",
    "            \n",
    "    else:\n",
    "        x = obsX[t+1]\n",
    "        current_beta = []\n",
    "        for i in range(len(states)):\n",
    "            accum = 0.0\n",
    "            for j in range(len(states)):\n",
    "                accum += trans[i, j] * emmit[j, x] * ahead_beta[j]\n",
    "            \n",
    "            current_beta.append(accum)\n",
    "            \n",
    "        ahead_beta = deepcopy(current_beta)\n",
    "    \n",
    "    print \"ahead_beta\", ahead_beta    \n",
    "    betas.insert(0, ahead_beta)\n",
    "\n",
    "## viterbi\n",
    "for t in range(len(obsX)):\n",
    "    p_states = [alphas[t][s] * betas[t][s] / p_obs for s in range(len(states))]\n",
    "    print p_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = ('Healthy', 'Fever')\n",
    "end_state = 'E'\n",
    " \n",
    "observations = ('normal', 'cold', 'dizzy')\n",
    " \n",
    "start_probability = {'Healthy': 0.6, 'Fever': 0.4}\n",
    " \n",
    "transition_probability = {\n",
    "   'Healthy' : {'Healthy': 0.69, 'Fever': 0.3, 'E': 0.01},\n",
    "   'Fever' : {'Healthy': 0.4, 'Fever': 0.59, 'E': 0.01},\n",
    "   }\n",
    " \n",
    "emission_probability = {\n",
    "   'Healthy' : {'normal': 0.5, 'cold': 0.4, 'dizzy': 0.1},\n",
    "   'Fever' : {'normal': 0.1, 'cold': 0.3, 'dizzy': 0.6},\n",
    "   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fwd_bkw(observations, states, start_prob, trans_prob, emm_prob, end_st):\n",
    "    # forward part of the algorithm\n",
    "    fwd = []\n",
    "    f_prev = {}\n",
    "    for i, observation_i in enumerate(observations):\n",
    "        f_curr = {}\n",
    "        for st in states:\n",
    "            if i == 0:\n",
    "                # base case for the forward part\n",
    "                prev_f_sum = start_prob[st]\n",
    "            else:\n",
    "                prev_f_sum = sum(f_prev[k]*trans_prob[k][st] for k in states)\n",
    "\n",
    "            f_curr[st] = emm_prob[st][observation_i] * prev_f_sum\n",
    "\n",
    "        fwd.append(f_curr)\n",
    "        f_prev = f_curr\n",
    "\n",
    "    p_fwd = sum(f_curr[k] * trans_prob[k][end_st] for k in states)\n",
    "    print p_fwd\n",
    "\n",
    "    # backward part of the algorithm\n",
    "    bkw = []\n",
    "    b_prev = {}\n",
    "    for i, observation_i_plus in enumerate(reversed(observations[1:]+(None,))):\n",
    "        b_curr = {}\n",
    "        for st in states:\n",
    "            if i == 0:\n",
    "                # base case for backward part\n",
    "                b_curr[st] = trans_prob[st][end_st]\n",
    "            else:\n",
    "                b_curr[st] = sum(trans_prob[st][l] * emm_prob[l][observation_i_plus] * b_prev[l] for l in states)\n",
    "            \n",
    "            print st, b_curr[st]\n",
    "            \n",
    "        bkw.insert(0,b_curr)\n",
    "        b_prev = b_curr\n",
    "        print\n",
    "\n",
    "    p_bkw = sum(start_prob[l] * emm_prob[l][observations[0]] * b_curr[l] for l in states)\n",
    "\n",
    "    # merging the two parts\n",
    "    posterior = []\n",
    "    for i in range(len(observations)):\n",
    "        print i, [(fwd[i][st], bkw[i][st], p_fwd) for st in states]\n",
    "        posterior.append({st: fwd[i][st] * bkw[i][st] / p_fwd for st in states})\n",
    "\n",
    "    assert p_fwd == p_bkw\n",
    "    return posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0003563832\n",
      "Healthy 0.01\n",
      "Fever 0.01\n",
      "\n",
      "Healthy 0.00249\n",
      "Fever 0.00394\n",
      "\n",
      "Healthy 0.00104184\n",
      "Fever 0.00109578\n",
      "\n",
      "0 [(0.3, 0.0010418399999999998, 0.00035638319999999995), (0.04000000000000001, 0.00109578, 0.00035638319999999995)]\n",
      "1 [(0.0892, 0.00249, 0.00035638319999999995), (0.03408, 0.00394, 0.00035638319999999995)]\n",
      "2 [(0.007518, 0.01, 0.00035638319999999995), (0.028120319999999997, 0.01, 0.00035638319999999995)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'Fever': 0.1229889624426741, 'Healthy': 0.8770110375573259},\n",
       " {'Fever': 0.3767719690490461, 'Healthy': 0.623228030950954},\n",
       " {'Fever': 0.7890472951586943, 'Healthy': 0.2109527048413057}]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def example():\n",
    "    return fwd_bkw(observations,\n",
    "                   states,\n",
    "                   start_probability,\n",
    "                   transition_probability,\n",
    "                   emission_probability,\n",
    "                   end_state)\n",
    "\n",
    "example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
